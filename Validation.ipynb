{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from dataprocess_lib0 import *\n",
    "from IPython.core.pylabtools import figsize\n",
    "import gc, json\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('../data/Google Analytics Customer Revenue Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 516 ms, total: 1.98 s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr1 = pd.read_pickle(PATH/'tr1_clean')\n",
    "tr2 = pd.read_pickle(PATH/'tr2_clean')\n",
    "tr3 = pd.read_pickle(PATH/'tr3_clean')\n",
    "tr4 = pd.read_pickle(PATH/'tr4_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tr4.copy()\n",
    "val['target'] = np.nan\n",
    "val['ret'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([tr1, tr2, tr3, val], axis=0, sort=False).reset_index(drop=True)\n",
    "train_val['interval_dates'] = train_val['interval_dates'].dt.days\n",
    "train_val['first_ses_from_the_period_start'] = train_val['first_ses_from_the_period_start'].dt.days\n",
    "train_val['last_ses_from_the_period_end'] = train_val['last_ses_from_the_period_end'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417575, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB model\n",
    "\n",
    "#### Parameters of 'isReturned' classficator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb1 = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"binary_logloss\",\n",
    "        \"max_leaves\": 256,\n",
    "        \"num_leaves\" : 15,\n",
    "        \"min_child_samples\" : 1,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"bagging_fraction\" : 0.9,\n",
    "        \"feature_fraction\" : 0.8,\n",
    "        \"bagging_frequency\" : 1           \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters of 'how_much_returned_will_pay' regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb2 = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\", \n",
    "        \"max_leaves\": 256,\n",
    "        \"num_leaves\" : 9,\n",
    "        \"min_child_samples\" : 1,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"bagging_fraction\" : 0.9,\n",
    "        \"feature_fraction\" : 0.8,\n",
    "        \"bagging_frequency\" : 1      \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation: Averaging of 10 [Classificator*Regressor] values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change objects to category type\n",
    "cat_train(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_val[train_val['target'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = train_val[train_val['target'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['target', 'ret', 'fullVisitorId']\n",
    "\n",
    "dtrain = lgb.Dataset(train.drop(target_cols, axis=1), label=train['ret'])\n",
    "\n",
    "dtrain_ret = lgb.Dataset(train.drop(target_cols, axis=1)[train['ret']==1], \n",
    "                         label=train['target'][train['ret']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_lgb_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predictions\n",
      "Interation number  0\n",
      "Interation number  1\n",
      "Interation number  2\n",
      "Interation number  3\n",
      "Interation number  4\n",
      "Interation number  5\n",
      "Interation number  6\n",
      "Interation number  7\n",
      "Interation number  8\n",
      "Interation number  9\n"
     ]
    }
   ],
   "source": [
    "print('Training and predictions')\n",
    "for i in range(10):\n",
    "    print('Interation number ', i)\n",
    "    lgb_model1 = lgb.train(params_lgb1, dtrain, num_boost_round=1200)\n",
    "    pr_lgb = lgb_model1.predict(dev.drop(target_cols, axis=1))\n",
    "    \n",
    "    lgb_model2 = lgb.train(params_lgb2, dtrain_ret, num_boost_round=368)\n",
    "    pr_lgb_ret = lgb_model2.predict(dev.drop(target_cols, axis=1))\n",
    "    \n",
    "    pr_lgb_sum = pr_lgb_sum + pr_lgb*pr_lgb_ret\n",
    "\n",
    "pr_final_lgb = pr_lgb_sum/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = tr4['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse_lgb = sqrt(mean_squared_error(targets, pr_final_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3166215786279411"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text vectorization + LGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def vectorize_text(tmp, max_features=None):\n",
    "    # tmp: pandas series \n",
    "    # output: numpy 2d-array (len(tmp), max_features)   \n",
    "    corpus = tmp[tmp.notnull()]\n",
    "    idx =corpus.index.values\n",
    "    vectorizer = CountVectorizer(max_features=max_features)\n",
    "    vectorizer.fit(corpus)\n",
    "    X = vectorizer.transform(corpus)\n",
    "    mat = np.zeros((len(tmp),max_features), dtype='int')\n",
    "    mat[idx,:] = X.toarray()    \n",
    "    print(vectorizer.get_feature_names())\n",
    "    #print(type(vectorizer))\n",
    "    return mat, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417575, 42)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = pd.read_pickle(PATH/'train_val_clean')\n",
    "train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val['combined'] = train_val['source'].str.cat(train_val['referralPath'], sep=\" \"). \\\n",
    "                        str.cat(train_val['networkDomain'],sep=\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2145', '3bb', '419', '4spnk9', 'about', 'ac', 'actcorp', 'ad', 'ads', 'advertise', 'airtelbroadband', 'alphabet', 'amazonaws', 'analytics', 'and', 'app', 'ar', 'as5580', 'asianet', 'at', 'au', 'awards', 'bbtec', 'bell', 'benefits', 'bezeqint', 'bg', 'blog', 'br', 'brand', 'brasiltelecom', 'btcentralplus', 'by', 'c10b14f9a69ff71b1b7a', 'ca', 'cable', 'can', 'cantv', 'chello', 'cn', 'co', 'cogentco', 'com', 'comcast', 'comcastbusiness', 'comments', 'copyright', 'cox', 'creators', 'cs', 'cz', 'de', 'deals', 'dev', 'direct', 'discounts', 'do', 'doubleclick', 'edu', 'en', 'es', 'fl', 'forum', 'fr', 'free', 'gb', 'get', 'go', 'golang', 'google', 'googleads', 'googleplex', 'googletopia', 'gopher', 'gr', 'gvt', 'he', 'head', 'hinet', 'home', 'how', 'hr', 'htm', 'html', 'hu', 'id', 'il', 'in', 'index', 'infinitum', 'inpage_launch', 'intl', 'ip', 'ipconnect', 'it', 'items', 'iw', 'ja', 'jobs', 'jp', 'lineups', 'logo', 'mail', 'megared', 'mobile', 'mountain', 'music', 'mx', 'ne', 'net', 'nl', 'ocn', 'od', 'offer', 'office', 'online', 'optonline', 'or', 'org', 'pagead', 'pe', 'permissions', 'ph', 'pk', 'pl', 'pldt', 'plus', 'policies', 'press', 'prod', 'proxad', 'pt', 'qiita', 'quora', 'qwest', 'rdsnet', 'reddit', 'resources', 'rima', 'ro', 'rr', 'rs', 'ru', 'sbcglobal', 'se', 'sfr', 'shirt', 'silicon', 'siliconvalley', 'sites', 'sk', 'space', 'speedy', 'store', 'stuff', 'superonline', 'sv', 'tde', 'tedata', 'telecom', 'telecomitalia', 'telekom', 'telesp', 'telia', 'telkom', 'th', 'the', 'things', 'to', 'totbb', 'tpnet', 'tr', 'ttnet', 'tw', 'ua', 'ucom', 'uk', 'using', 'valley', 'vdc', 'veloxzone', 'verizon', 'vi', 'video', 'viettel', 'view', 'virginm', 'virtua', 'visit', 'vn', 'vnpt', 'vodafone', 'wanadoo', 'web', 'where_to_buy_the_golang_gopher_plush', 'ykei_mrn', 'youtube', 'yt', 'za', 'zh']\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "tmp = train_val['combined']\n",
    "mat_combined, _ = vectorize_text(tmp, max_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = train_val.join(pd.DataFrame(mat_combined, dtype='object', \n",
    "                                    columns=['sourc_referralP_network_{}'.format(i) for i in range(200)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.drop(['source', 'referralPath', 'networkDomain', 'combined'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.tabular import *\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in transfering fullVisitorId type\n",
      "error in transfering city type\n",
      "error in transfering operatingSystem type\n",
      "error in transfering metro type\n",
      "error in transfering region type\n",
      "error in transfering channelGrouping type\n",
      "error in transfering country type\n",
      "error in transfering medium type\n",
      "error in transfering keyword type\n",
      "error in transfering browser type\n",
      "error in transfering deviceCategory type\n",
      "error in transfering continent type\n"
     ]
    }
   ],
   "source": [
    "int_cols = []\n",
    "for col in train_val.columns:\n",
    "    try:\n",
    "        train_val[col].dropna().astype(int)\n",
    "        int_cols.append(col)\n",
    "    except:\n",
    "        print('error in transfering {} type'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'browser',\n",
       " 'channelGrouping',\n",
       " 'city',\n",
       " 'continent',\n",
       " 'country',\n",
       " 'deviceCategory',\n",
       " 'fullVisitorId',\n",
       " 'keyword',\n",
       " 'medium',\n",
       " 'metro',\n",
       " 'operatingSystem',\n",
       " 'region'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = set(train_val.columns)-set(int_cols)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_val['gclId'] = train_val['gclId'].astype(str)\n",
    "train_val['gclId'][train_val['gclId']!='nan'] = 1 \n",
    "train_val['gclId'][train_val['gclId']=='nan'] = 0 \n",
    "train_val.rename(columns={'gclId':'gclId_captured'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051373, 239)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = train_val.iloc[range(0, (len(train_val))-len(tr4))]\n",
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366202, 239)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev2 = train_val.iloc[range(len(train_val)-len(tr4), len(train_val))]\n",
    "dev2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['target', 'ret', 'fullVisitorId']\n",
    "\n",
    "dtrain2 = lgb.Dataset(train2.drop(target_cols, axis=1), train2['ret'])\n",
    "\n",
    "dtrain_ret2 = lgb.Dataset(train2.drop(target_cols, axis=1)[train2['ret']==1], \\\n",
    "                         label=train2['target'][train2['ret']==1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_lgb_sum2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predictions\n",
      "Interation number  0\n",
      "Interation number  1\n",
      "Interation number  2\n",
      "Interation number  3\n",
      "Interation number  4\n",
      "Interation number  5\n",
      "Interation number  6\n",
      "Interation number  7\n",
      "Interation number  8\n",
      "Interation number  9\n"
     ]
    }
   ],
   "source": [
    "print('Training and predictions')\n",
    "for i in range(10):\n",
    "    print('Interation number ', i)\n",
    "    lgb_model3 = lgb.train(params_lgb1, dtrain2, num_boost_round=1200)\n",
    "    pr_lgb2 = lgb_model3.predict(dev2.drop(target_cols, axis=1))\n",
    "    \n",
    "    lgb_model4 = lgb.train(params_lgb2, dtrain_ret2, num_boost_round=368)\n",
    "    pr_lgb_ret2 = lgb_model4.predict(dev2.drop(target_cols, axis=1))\n",
    "    \n",
    "    pr_lgb_sum2 = pr_lgb_sum2 + pr_lgb2 * pr_lgb_ret2\n",
    "\n",
    "pr_final_lgb2 = pr_lgb_sum2 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3160319850511174"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse_lgb = sqrt(mean_squared_error(targets, pr_final_lgb2))\n",
    "rmse_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
