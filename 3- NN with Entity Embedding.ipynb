{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model as KerasModel\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Reshape\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('col_types.pickle', 'rb')\n",
    "(cat_cols, num_cols) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols) + len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('feature_train_data_v2.pickle', 'rb')\n",
    "(X, y1, y2) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051373"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(X) - 366202 # use tr4 as validation set\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:train_size]\n",
    "X_val = X[train_size:]\n",
    "y_train = y1[:train_size]\n",
    "y_val = y1[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(X, y, n):\n",
    "    '''random samples'''\n",
    "    num_row = X.shape[0]\n",
    "    indices = np.random.randint(num_row, size=n)\n",
    "    return X.iloc[indices, :], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train = sample(X_train, y_train, 200000)  # Simulate data sparsity\n",
    "#print(\"Number of samples used for training: \" + str(y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        y_val[y_val < 0] = 0\n",
    "        guessed_sales = self.guess(X_val)       \n",
    "        result = sqrt(mean_squared_error(guessed_sales, y_val))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features(X):\n",
    "    X_list = []\n",
    "    for i in range(X.shape[1]):  \n",
    "         \n",
    "        X_list.append(X.iloc[:,i].values)\n",
    "        \n",
    "    return X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding size (cat data)\n",
    "def emb_size(n_cat):\n",
    "   # min(50, (n_cat//2)+1)\n",
    "   return min(round(1.6*n_cat**0.56), 60)\n",
    "  \n",
    "def embed_shape(ps):\n",
    "    n_cat = max(ps) + 1 \n",
    "    size = emb_size(n_cat)\n",
    "    return [n_cat, size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_cols = ['fullVisitorId', 'networkDomain','gclId']\n",
    "#cat_cols = [x for x in cat_cols if x not in drop_cols]\n",
    "#X_train.drop(drop_cols, axis=1,inplace=True)\n",
    "#X_val.drop(drop_cols, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_with_EntityEmbeddings(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, cat_cols, num_cols):\n",
    "        super().__init__()\n",
    "        self.epochs = 3   \n",
    "        self.cat_cols = cat_cols\n",
    "        self.num_cols = num_cols\n",
    "       #self.checkpointer = ModelCheckpoint(filepath=\"best_model_weights.hdf5\", verbose=1, save_best_only=True)\n",
    "        self.max_log_y = max(np.max(y_train),np.max(y_val))\n",
    "        self.__build_keras_model()\n",
    "        self.fit(X_train, y_train, X_val, y_val)        \n",
    "    \n",
    "    def preprocessing(self, X):\n",
    "        X_list = split_features(X)\n",
    "        return X_list\n",
    "    \n",
    "    def __build_keras_model(self):\n",
    "        # embedding layer\n",
    "          \n",
    "        input_model = []        \n",
    "        output_embeddings = []\n",
    "        for col in X_train.columns:\n",
    "            if col in num_cols:\n",
    "                input_num = Input(shape=(1,),dtype='float32')\n",
    "                output_num = Dense(1)(input_num)\n",
    "            \n",
    "                input_model.append(input_num)\n",
    "                output_embeddings.append(output_num)\n",
    "            \n",
    "            elif col in cat_cols:\n",
    "                input_cat = Input(shape=(1,),dtype='float32')\n",
    "                x_all = pd.concat([X_train[col], X_val[col]])\n",
    "                ncat, entities = embed_shape(x_all)\n",
    "                print(col, ncat, entities)\n",
    "                output_cat = Embedding(ncat, entities, name = col)(input_cat)                \n",
    "                output_cat = Reshape(target_shape=(entities,))(output_cat)\n",
    "            \n",
    "                input_model.append(input_cat)\n",
    "                output_embeddings.append(output_cat)   \n",
    "        \n",
    "    \n",
    "        output_model = Concatenate()(output_embeddings)\n",
    "        #print(output_model)\n",
    "        # Layer 1\n",
    "        output_model = Dense(1000, kernel_initializer='uniform')(output_model)        \n",
    "        output_model = Activation('relu')(output_model)\n",
    "        print(output_model)\n",
    "        # Layer 2\n",
    "        output_model = Dense(500, kernel_initializer='uniform')(output_model)       \n",
    "        output_model = Activation('relu')(output_model)\n",
    "        # Output layer\n",
    "        output_model = Dense(1)(output_model)       \n",
    "        output_model = Activation('sigmoid')(output_model)\n",
    "        \n",
    "        self.model = KerasModel(inputs=input_model, outputs=output_model)\n",
    "        \n",
    "        self.model.compile(loss='mean_absolute_error',optimizer='adam')\n",
    "           \n",
    "    def _val_for_fit(self, val):\n",
    "        val = val / self.max_log_y\n",
    "        return val\n",
    "       \n",
    "    def _val_for_pred(self, val):\n",
    "        return val * self.max_log_y\n",
    "       \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        #self.model.fit(self.preprocessing(X_train), self._val_for_fit(y_train),\n",
    "        #               validation_data=(self.preprocessing(X_val), self._val_for_fit(y_val)),\n",
    "        #               epochs=self.epochs, batch_size=64,\n",
    "        #               callbacks=[self.checkpointer],\n",
    "        #               )        \n",
    "        self.model.load_weights('best_model_weights.hdf5')\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "        \n",
    "    def guess(self, features):\n",
    "        features = self.preprocessing(features)\n",
    "        result = self.model.predict(features).flatten()\n",
    "        return self._val_for_pred(result)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullVisitorId 1396370 60\n",
      "networkDomain 42952 60\n",
      "city 980 60\n",
      "operatingSystem 26 10\n",
      "metro 124 24\n",
      "region 489 51\n",
      "channelGrouping 8 5\n",
      "referralPath 3099 60\n",
      "country 228 33\n",
      "source 348 42\n",
      "medium 7 5\n",
      "keyword 4512 60\n",
      "browser 135 25\n",
      "gclId 54282 60\n",
      "deviceCategory 3 3\n",
      "continent 6 4\n",
      "sessionQualityDim 100 21\n",
      "Tensor(\"activation_6/Relu:0\", shape=(None, 1000), dtype=float32)\n",
      "Result on validation data:  0.31876424873585285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NN_with_EntityEmbeddings at 0x7f32bb488f60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_with_EntityEmbeddings(X_train, y_train, X_val, y_val, cat_cols, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
